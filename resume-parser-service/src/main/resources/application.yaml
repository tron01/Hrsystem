server:
  port: 8083

spring:
  ai:
    ollama:
      base-url: http://localhost:11434
      chat:
        model: resume-sf # your custom model created from Modelfile
        options:
          temperature: 0
          keep-alive: 5m

  application:
    name: resume-parser-service
  threads:
    virtual:
      enabled: true
  kafka:
    bootstrap-servers: localhost:9092
    consumer:
      group-id: resume-parser-group
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      auto-offset-reset: earliest
      properties:
        spring.json.value.default.type: com.Abhijith.resume_parser_service.kafka.event.ResumeParseEvent
        spring.json.trusted.packages: "com.Abhijith.resume_parser_service.kafka.event"
        spring.json.use.type.headers: false
    listener:
      ack-mode: manual

  data:
    mongodb:
      uri: mongodb://localhost:27017/applicationdb

eureka:
  client:
    service-url:
      defaultZone: http://localhost:8761/eureka/
    register-with-eureka: true
    fetch-registry: true
  instance:
    prefer-ip-address: true

kafka:
  topics:
    resume-parse: resume-parse-topic

management:
  tracing:
    sampling:
      probability: 1.0
  endpoints:
    web:
      exposure:
        include: "*"

logging:
  level:
    com.Abhijith.resume_parser_service: DEBUG
  pattern:
    level: "%5p [traceId=%X{traceId} spanId=%X{spanId}] %m%n"
